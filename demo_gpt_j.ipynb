{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1cQA8rf3jRFwrfW0xGDgvAIiHzjANZAH3",
      "authorship_tag": "ABX9TyO96pEncqBxkoaeMPkl8duE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abaranguer/lab-aina/blob/main/demo_gpt_j.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT-J chatbot\n",
        "\n",
        "### https://www.eleuther.ai/artifacts/gpt-j\n",
        "### https://huggingface.co/docs/transformers/model_doc/gptj\n",
        "### https://medium.com/@maliahrajan/revolutionise-your-q-a-bot-with-gpt-j-the-open-source-game-changer-as-a-replacement-for-gpt-3-216bc4362b53"
      ],
      "metadata": {
        "id": "JlI2TATozPiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPTJForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "\n",
        "print('Using device:', device)\n",
        "torch.device(device)\n",
        "\n",
        "model = GPTJForCausalLM.from_pretrained(\n",
        "    \"EleutherAI/gpt-j-6B\",\n",
        "    revision=\"float16\",\n",
        "    dtype=torch.float16,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiGVRZN8zZbB",
        "outputId": "c93d9c6c-2fb8-44ea-9912-b8c3bf369fb9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at EleutherAI/gpt-j-6B were not used when initializing GPTJForCausalLM: ['transformer.h.0.attn.bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.10.attn.bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.12.attn.bias', 'transformer.h.12.attn.masked_bias', 'transformer.h.13.attn.bias', 'transformer.h.13.attn.masked_bias', 'transformer.h.14.attn.bias', 'transformer.h.14.attn.masked_bias', 'transformer.h.15.attn.bias', 'transformer.h.15.attn.masked_bias', 'transformer.h.16.attn.bias', 'transformer.h.16.attn.masked_bias', 'transformer.h.17.attn.bias', 'transformer.h.17.attn.masked_bias', 'transformer.h.18.attn.bias', 'transformer.h.18.attn.masked_bias', 'transformer.h.19.attn.bias', 'transformer.h.19.attn.masked_bias', 'transformer.h.2.attn.bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.20.attn.bias', 'transformer.h.20.attn.masked_bias', 'transformer.h.21.attn.bias', 'transformer.h.21.attn.masked_bias', 'transformer.h.22.attn.bias', 'transformer.h.22.attn.masked_bias', 'transformer.h.23.attn.bias', 'transformer.h.23.attn.masked_bias', 'transformer.h.24.attn.bias', 'transformer.h.24.attn.masked_bias', 'transformer.h.25.attn.bias', 'transformer.h.25.attn.masked_bias', 'transformer.h.26.attn.bias', 'transformer.h.26.attn.masked_bias', 'transformer.h.27.attn.bias', 'transformer.h.27.attn.masked_bias', 'transformer.h.3.attn.bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.bias', 'transformer.h.9.attn.masked_bias']\n",
            "- This IS expected if you are initializing GPTJForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPTJForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def intro():\n",
        "  print('''\n",
        "  Hi!\n",
        "  I'm GPT-J, a large language model trained by EleutherAI.\n",
        "  How can I help you today?\n",
        "\n",
        "  (Enter *END* to finish session)\n",
        "\n",
        "  ''')\n",
        "\n",
        "def mainLoop():\n",
        "  follow = True\n",
        "  prompt = ''\n",
        "\n",
        "  while follow:\n",
        "    print('You: ')\n",
        "    prompt = input()\n",
        "    if prompt == '*END*':\n",
        "      follow = False\n",
        "    else:\n",
        "      prompt = prompt.strip()\n",
        "\n",
        "      if prompt != '':\n",
        "        # Added Q: and A: to the prompt to encourage the model to follow the format\n",
        "        prompt = 'Q: ' + prompt + '\\nA:'\n",
        "        input_ids = tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\").input_ids\n",
        "\n",
        "        gen_tokens = model.generate(\n",
        "            input_ids,\n",
        "            do_sample=True,\n",
        "            temperature=0.9,\n",
        "            max_length=100,\n",
        "        )\n",
        "\n",
        "        queryAndAnswer = tokenizer.batch_decode(\n",
        "                          gen_tokens,\n",
        "                          skip_special_tokens=True)[0]\n",
        "\n",
        "        # Handle cases where the model doesn't output \"A:\"\n",
        "        if \"A:\" in queryAndAnswer:\n",
        "            answer = queryAndAnswer.split(\"A:\")[1].strip()\n",
        "            if \"Q:\" in answer:\n",
        "              answer = answer.split(\"Q:\")[0]\n",
        "        else:\n",
        "            # Default response\n",
        "            answer = \"Sorry, I couldn't generate a response for that.\"\n",
        "\n",
        "\n",
        "        print('Me: ', answer)\n",
        "\n",
        "def goodbye():\n",
        "  print('Goodbye!')"
      ],
      "metadata": {
        "id": "QcsOYn3s-Z4-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  intro()\n",
        "  mainLoop()\n",
        "  goodbye()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1aqCNT7gR-j",
        "outputId": "09146a4d-226a-4678-e330-912766399ec9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Hi!\n",
            "  I'm GPT-J, a large language model trained by EleutherAI.\n",
            "  How can I help you today?\n",
            "\n",
            "  (Enter *END* to finish session)\n",
            "\n",
            "  \n",
            "You: \n",
            "Hi! Talk me about Barcelona\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Me:  Barcelona is the capital of Catalonia. It is the capital of the region and one of the most important cities in Spain thanks to its historical and cultural heritage.\n",
            "\n",
            "\n",
            "You: \n",
            "Yes, it's true. I live in Barcelona\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Me:  Not in Barcelona, but in Mallorca.\n",
            "\n",
            "You: \n",
            "Sure? It's a very nice island!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Me:  Oh, it's the best island in the world! And all of the houses are pink.\n",
            "\n",
            "You: \n",
            "I've seen some green houses, too\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Me:  It's called a 'Garden Shed', and is the perfect place to keep your garden seedlings until they are big enough to plant. Or you can move them out into the garden.\n",
            "\n",
            "\n",
            "You: \n",
            "You are a gardenier?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Me:  Yeah, I have always been into the natural. I love to grow stuff. I love the natural, it's so interesting to people too, because it's not like you just pick the flowers off the plant, and you have no real idea what you are planting.\n",
            "\n",
            "\n",
            "You: \n",
            "True, true. The living stuff is the best. Plants are the most incredible beings of the Creatioon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Me:  And then they eat the fruits.\n",
            "\n",
            "\n",
            "You: \n",
            "Yes, I specially like the bananas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Me:  Yes, I like them too.\n",
            "\n",
            "\n",
            "You: \n",
            "It's a little bit surrealist chat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Me:  We had a little bit of a time.\n",
            "\n",
            "You: \n",
            "Well, I have some tasks to do. Talking tou tou has been a  charming experience, baut I have to leave. Bye!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Me:  No! I want to talk to you.\n",
            "\n",
            "You: \n",
            "*END*\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}