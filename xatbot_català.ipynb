{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPKLSgym4BaLx9fuKh+3+N0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abaranguer/lab-aina/blob/main/xatbot_catal%C3%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XatBot Català - GPT-J + AINA"
      ],
      "metadata": {
        "id": "2HHdTSK0fmHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ctranslate2 pyonmttok"
      ],
      "metadata": {
        "id": "zSK6RK5ziDiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ctranslate2\n",
        "import pyonmttok\n",
        "from huggingface_hub import snapshot_download\n",
        "from transformers import GPTJForCausalLM, AutoTokenizer\n",
        "import torch"
      ],
      "metadata": {
        "id": "O2zk4FtQkdcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AINA\n",
        "class Translators:\n",
        "  def __init__(self):\n",
        "    model_dir_en_ca = snapshot_download(repo_id=\"projecte-aina/aina-translator-en-ca\", revision=\"main\", local_dir=\"/content/aina/en-ca\")\n",
        "    model_dir_ca_en = snapshot_download(repo_id=\"projecte-aina/aina-translator-ca-en\", revision=\"main\", local_dir=\"/content/aina/ca-en\")\n",
        "\n",
        "    self.tokenizerEnCa = pyonmttok.Tokenizer(mode=\"none\", sp_model_path = model_dir_en_ca + \"/spm.model\")\n",
        "    self.tokenizerCaEn = pyonmttok.Tokenizer(mode=\"none\", sp_model_path = model_dir_ca_en + \"/spm.model\")\n",
        "\n",
        "    self.tranlatorCa2En = ctranslate2.Translator(model_dir_ca_en)\n",
        "    self.tranlatorEn2Ca = ctranslate2.Translator(model_dir_en_ca)\n",
        "\n",
        "  def translateCa2En(self, text):\n",
        "    tokenized = self.tokenizerCaEn.tokenize(text)\n",
        "    translated = self.tranlatorCa2En.translate_batch([tokenized[0]])\n",
        "    return self.tokenizerCaEn.detokenize(translated[0][0]['tokens'])\n",
        "\n",
        "  def translateEn2Ca(self, text):\n",
        "    tokenized = self.tokenizerEnCa.tokenize(text)\n",
        "    translated = self.tranlatorEn2Ca.translate_batch([tokenized[0]])\n",
        "    return self.tokenizerEnCa.detokenize(translated[0][0]['tokens'])"
      ],
      "metadata": {
        "id": "Dz6WXDYtfwUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT-J\n",
        "class XatBotGPTJ_AINA:\n",
        "  def __init__(self, isLocal):\n",
        "    self.translators = Translators()\n",
        "    self.device = \"cuda\"\n",
        "\n",
        "    modelName = \"EleutherAI/gpt-j-6B\"\n",
        "    model_save_dir = \"/content/gpt-j-6B\" # Define model_save_dir here\n",
        "\n",
        "    self.model = None\n",
        "\n",
        "    if not isLocal:\n",
        "      # Load the model\n",
        "      self.model = GPTJForCausalLM.from_pretrained(\n",
        "        modelName,\n",
        "        revision=\"float16\",\n",
        "        torch_dtype=torch.float16,\n",
        "      )\n",
        "      # Save the model to a local directory\n",
        "      self.model.save_pretrained(model_save_dir)\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(modelName)\n",
        "      self.tokenizer.save_pretrained(model_save_dir)\n",
        "    else:\n",
        "      # Load the model from the local directory\n",
        "      self.model = GPTJForCausalLM.from_pretrained(model_save_dir).to(self.device)\n",
        "      # self.tokenizer = AutoTokenizer.from_pretrained(model_save_dir)\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(model_save_dir)\n",
        "\n",
        "  def xatBotSession(self):\n",
        "    print(\"Hola, sóc el Xatbot GptJ-Aina.\")\n",
        "    print(\"Per a acabar la sessió, escriu 'Adéu'.\")\n",
        "    print(\"Parlem del que vulguis.\")\n",
        "\n",
        "    follow = True\n",
        "    while follow:\n",
        "      queryCat = input()\n",
        "      if queryCat.upper() == \"ADÉU\":\n",
        "        print(\"Ha estat un plaer parlar amb tu. Adéu!\")\n",
        "        follow = False\n",
        "      else:\n",
        "        query = self.translators.translateCa2En(queryCat)\n",
        "        answerEn = self.getAnswer(query)\n",
        "        answer = self.translators.translateEn2Ca(answerEn)\n",
        "        print(\"XatBot:\", answer)\n",
        "\n",
        "  def getAnswer(self, query):\n",
        "    input_ids = self.tokenizer(\"Q: \" + query + \"\\nA:\",return_tensors=\"pt\").input_ids.to(self.device)\n",
        "\n",
        "    gen_tokens = self.model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        temperature=0.9,\n",
        "        max_length=1024)\n",
        "\n",
        "    queryAndAnswer = self.tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)[0]\n",
        "    answerAndQuery = queryAndAnswer.split(\"A:\")[1].strip()\n",
        "    answer = answerAndQuery.split(\"Q:\")[0].strip()\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "812qFg0qkTrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  xatBot = XatBotGPTJ_AINA(True)\n",
        "  xatBot.xatBotSession()"
      ],
      "metadata": {
        "id": "WNkTqW1NiTSH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}